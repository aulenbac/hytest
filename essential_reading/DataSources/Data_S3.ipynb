{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data / Cloud Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the main storage locations for HyTest data is in '_The Cloud_'. This is sometimes referred to as **'Object Storage'**.  The data is kept in datacenter(s) which makes it easily available to network-connected devices. The main advantage of doing this is that if your compute engine is also in that same datacenter (as is the case for many JupyterHub nodes), the data doesn't have to go very far to get to the compute power.  This brings the computation to the data, rather than shipping large datasets across the internet to get to the compute engine. \n",
    "\n",
    "[S3](https://aws.amazon.com/s3/) is Amazon's implementation of object storage, which pairs with the Amazon (AWS) nodes on which the Jupter Hub runs. What follows is a brief demo of how S3 data is accessed (both read and write), and some pitfalls to watch out for.\n",
    "\n",
    "The easiest way to access S3 data from within a Python program is via \n",
    "[fsspec](https://filesystem-spec.readthedocs.io/en/latest/) -- a layer of \n",
    "abstraction that lets us \n",
    "interact with arbitrary storage mechanisms as if they are conventional file systems.  \n",
    "It makes S3 'look' like a conventional file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access / Profile\n",
    "The permissions scheme for S3 allows for anonymous/global read access, as well as secured access via specific credentials.  \n",
    "\n",
    "We'll look at generic workflows using an anonymous-access bucket, then finish off with some private/credentialed operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anonymous Reads\n",
    "\n",
    "A lot of data is available for global read, which does not require credentials or a profile. In this case, just set `anon=True` when plumbing the `fsspec` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "# Create a reference to a globally-readable space\n",
    "fs = fsspec.filesystem(\n",
    "    's3', \n",
    "    anon=True   # Does not require credentials\n",
    "    )\n",
    "\n",
    "fs.ls('s3://noaa-nwm-retrospective-2-1-zarr-pds/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other filesystem-like operations: \n",
    "\n",
    "# glob = wildcard match:\n",
    "fs.glob(\"s3://noaa-nwm-retrospective-2-1-zarr-pds/*.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata about a file\n",
    "fs.info('noaa-nwm-retrospective-2-1-zarr-pds/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use open() to get something that behaves like a file handle for low-level Python read/write operations:\n",
    "with fs.open('noaa-nwm-retrospective-2-1-zarr-pds/index.html') as f:\n",
    "    # print first 5 lines...\n",
    "    for i in range(0,5):\n",
    "        line = f.readline()\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fsspec` library lets you do other common file operations (provided you have adequate premissions), see the [API documentation](https://filesystem-spec.readthedocs.io/en/latest/api.html) for details.\n",
    "Examples:\n",
    "* `mkdir` -- makes a new directory / folder\n",
    "* `mv` -- moves/renames a file or folder\n",
    "* `rm` -- removes a file or folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if what you need is something that looks like a file **name** or a **path** (as opposed to a file **handle**)... you may need to instruct `fsspec` to `map` the S3 path.  Like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "m = fs.get_mapper('s3://noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr')\n",
    "g = zarr.convenience.open_consolidated(m)\n",
    "print(g.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING !!!!**\n",
    "\n",
    "We are deliberately using `zarr` commands that read **only** the metadata, and not the full data\n",
    "set.  This is a very, _very_, **very** large dataset, which you don't want to load\n",
    "over the network to your desktop.  Execute full data read operations only if this notebook is being hosted \n",
    "and run out of the same AWS center where the data lives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Good News\n",
    "The good news about some of the larger science-oriented libraries (xarray, dask, pandas, zarr, etc), is that they **automatically** handle the `fsspec` operations for you **IF YOUR ACCESS IS ANONYMOUS**.  So a workflow like this:\n",
    "```python\n",
    "fs = fsspec.filesystem('s3', anon=True)\n",
    "m = fs.get_mapper('s3://noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr')\n",
    "dataset = xr.open_zarr(m, consolidated=True)\n",
    "```\n",
    "Can actually be simplified to:\n",
    "```python\n",
    "dataset = xr.open_zarr('s3://noaa-nwm-retrospective-2-1-zarr-pds/chrtout.zarr', consolidated=True)\n",
    "```\n",
    "\n",
    "Note that this is a feature of \n",
    "[very specific libraries](https://filesystem-spec.readthedocs.io/en/latest/#who-uses-fsspec).  If you are\n",
    "reading or writing S3 locations outside of those libraries, you'll need to handle the `fsspec` maps yourself using `get_mapper()`.  \n",
    "\n",
    "If you will be accessing a S3 storage location with `anon=False` (i.e. with credentials), then you will need to set up\n",
    "'longhand' with a mapper from `getmapper()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credentialed Access\n",
    "For most data, permissions are set by the owners of that data, and credentials assigned to a 'profile'. \n",
    "\n",
    "Credentials are stored outside of the Python program (typically in a master file in your ``HOME` folder on the compute/jupyter server).  You need to have this set up beforehand, and is usually achieved by copying specific credentials into the right spot. \n",
    "\n",
    "From the shell / command-line, it might look something like this:\n",
    "```text\n",
    "cp -R /shared/users/lib/.aws $HOME/.aws\n",
    "```\n",
    "The `.aws` folder and files will be provided by the bucket owner.  Within that `.aws` folder is a `config` file which includes lines something like this:\n",
    "\n",
    "```text\n",
    "[nhgf-development]\n",
    "aws_access_key_id = XXXXXXXXXXXXXXXX\n",
    "aws_secret_access_key = <magic key>\n",
    "\n",
    "[default]\n",
    "aws_access_key_id = XXXXXXXXXXXXXXXX\n",
    "aws_secret_access_key = <magic key>\n",
    "```\n",
    "The names in brackes are '_profiles_', which describe the access pattern for the S3 buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "# Set profile via environment variable -- this ensures that all AWS-capable \n",
    "# functions can get the right profile without it being explicitly specified.\n",
    "os.environ['AWS_PROFILE'] = 'nhgf-development'\n",
    "\n",
    "import fsspec\n",
    "\n",
    "fs = fsspec.filesystem(\n",
    "    's3',                    # Use S3 protocol\n",
    "    anon=False,              # Force fsspec to find credentials\n",
    "    skip_instance_cache=True # Insist that we don't cache locally ; important for fs that can change\n",
    ")\n",
    "# the 'fs' object now gives us filesystem-like methods to use, like 'ls'\n",
    "fs.ls('s3://nhgf-development/workspace/')\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With greater permissions, you may be able to do more destructive activities (overwriting, removing, etc).  The essential form\n",
    "is the same as it is for anonymous access, but  you should take care with S3 locations where you have the ability to affect\n",
    "existing files and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('hytest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4100cc85ffefb381c538d28dd18cb927e5a99f05bbed6aaad5313d7bb1c2079e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
