{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers :: NWM 'Standard Suite (v1)' Benchmark\n",
    "\n",
    "These are custom-defined Python objects which bundle common functions to be run against time-series data. \n",
    "\n",
    "These statistics adapted from the originals in <https://github.com/USGS-python/hytest-evaluation-workflows/blob/main/gallery/streamflow/02_nwm_benchmark_analysis.ipynb> \n",
    "\n",
    "<details>\n",
    "  <summary>Guide to pre-requisites and learning outcomes...&lt;click to expand&gt;</summary>\n",
    "  \n",
    "  <table>\n",
    "    <tr>\n",
    "      <td>Pre-Requisites\n",
    "      <td>To get the most out of this notebook, you should already have an understanding of these topics: \n",
    "        <ul>\n",
    "        <li>pre-req one\n",
    "        <li>pre-req two\n",
    "        </ul>\n",
    "    <tr>\n",
    "      <td>Expected Results\n",
    "      <td>At the end of this notebook, you should be able to: \n",
    "        <ul>\n",
    "        <li>outcome one\n",
    "        <li>outcome two\n",
    "        </ul>\n",
    "  </table>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE:  \n",
    "This notebook describes how to use the 'helper' library that we've put together to bundle\n",
    "the following statistics.  You are not obligated to use it for outside work -- it is a convenience interface to these\n",
    "standard metrics, meant to make these tutorials easier.  The computation of each is possible using your own code, \n",
    "custom code (see the above-mentioned reference notebook), or even external \n",
    "libraries ([`hydroeval`](https://github.com/thibhlln/hydroeval) is one such).\n",
    "\n",
    "\n",
    "## The Metrics:\n",
    "This suite of metrics describes the NWM benchmark:\n",
    "| Metric                              | Reference                                                           |\n",
    "| ----- | ----- |\n",
    "| Nash-Sutcliffe efficiency (NSE)     | Nash, J. E., & Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I—A discussion of principles. Journal of hydrology, 10(3), 282-290. https://www.sciencedirect.com/science/article/pii/0022169470902556?via%3Dihub\n",
    "| Kling-Gupta efficiency (KGE)        | Gupta, H. V., Kling, H., Yilmaz, K. K., & Martinez, G. F. (2009).  Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. Journal of hydrology, 377(1-2), 80-91. https://www.sciencedirect.com/science/article/pii/S0022169409004843 |\n",
    "| logNSE                              | Oudin, L., Andréassian, V., Mathevet, T., Perrin, C., & Michel, C. (2006). Dynamic averaging of rainfall‐runoff model simulations from complementary model parameterizations. Water Resources  Research, 42(7).|\n",
    "| percent bias                        | A measure of the mean tendency of simulated values to be greater or less than associated observed values, units of percent |\n",
    "| ratio of standard deviation         | standard deviation of simulated values divided by the standard deviation of observed values |\n",
    "| Pearson Correlation                 | K. Pearson (1896, 1900, 1920)                                       |\n",
    "| Spearman Correlation                | Charles Spearman (1904, 1910)                                       |\n",
    "| percent bias in midsegment slope of the flow-duration curve (FDC) between Q20-Q70 | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC low-segment volume (Q0-Q30) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC high-segment volume (Q98-Q100) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "\n",
    "\n",
    "This notebook will briefly describe each of the above metrics, and show some results using sample data. The specific code to implement each metric is available in the helper library -- some of the important details of coding these metrics is included as notes in this notebook.  These are included for those who would like to adapt the code or create similar metrics using their own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access to helper library\n",
    "%run ../setup.ipynb\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "First thing we need is some sample data... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"TestData.csv\", index_col='date').dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Benchmark Code\n",
    "Import the specific benchmark you want to use.  We have a few helper benchmarks available (see [this notebook](./xx_Benchmarks_General.ipynb) for more information on how benchmark helpers can be used). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HyTEST.benchmarks.NWMStandardSuite import NWMStandardSuite as Benchmark\n",
    "nwm = Benchmark.from_df(df, 'obs', 'nwm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These statements imported a symbol (`Benchmark`) from the `HyTEST.benchmarks.NWMStandardSuite` helper library. \n",
    "\n",
    "That name/symbol is a Python `Object`, which means it can hold both data and the methods which operate on that data. Because those things all go together logically, we've bundled them in this way. \n",
    "\n",
    "Note that the new object is called `nwm`.  We can now use that to access the data, as well as common stats computed over that specific data. \n",
    "\n",
    "The `NWMStandardSuite` benchmark is an extension of the interface described in the 'General Benchmark' notebook.  Consult that document for some details on why/how objects are used here instead of static procedures.   This notebook will focus on the ten specific statistics specified in the above table. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on each benchmark component:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSE\n",
    "| Metric | Reference |\n",
    "| ----- | ----- |\n",
    "| Nash-Sutcliffe efficiency (NSE)     | Nash, J. E., & Sutcliffe, J. V. (1970). River flow forecasting through conceptual models part I—A discussion of principles. Journal of hydrology, 10(3), 282-290. https://www.sciencedirect.com/science/article/pii/0022169470902556?via%3Dihub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: \n",
    "nwm.NSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special note on NSE** &mdash; A component within the calculation of NSE is _variance_ computed over the \n",
    "observed values. Different python libraries calculated this in different ways, so some of the details matter\n",
    "when calculating.  \n",
    "In particular, `numpy` assumes that `ddof` (Delta Degrees of Freedom) \n",
    "is [zero](https://numpy.org/doc/stable/reference/generated/numpy.var.html), while others (notably, `pandas`), \n",
    "assumes a `ddof` of [one](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.var.html).  \n",
    "\n",
    "Without explicit instructions, these two common libraries will return different results for the '_same_' calculation. \n",
    "If you should decide to build your own functions involving variance, it will matter how you calculate that value: \n",
    "```python\n",
    "df['obs'].var()  # using pandas\n",
    "```\n",
    "will yield a **different** result than\n",
    "```python\n",
    "np.var(df['obs']) # using numpy\n",
    "```\n",
    "The key (in either case) is to **explicitly** define the `ddof`: \n",
    "```python\n",
    "df['obs'].var(ddof=0)\n",
    "# or\n",
    "np.var(df['obs'], ddof=0)\n",
    "```\n",
    "The **NSE** benchmark helper we provide explicitly uses `ddof=0` to compute variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KGE\n",
    "| Metric                              | Reference                                                           |\n",
    "| ----- | ----- |\n",
    "| Kling-Gupta efficiency (KGE)        | Gupta, H. V., Kling, H., Yilmaz, K. K., & Martinez, G. F. (2009).  Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. Journal of hydrology, 377(1-2), 80-91. https://www.sciencedirect.com/science/article/pii/S0022169409004843 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example:\n",
    "nwm.KGE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logNSE\n",
    "| Metric                              | Reference                                                           |\n",
    "| ----- | ----- |\n",
    "| logNSE                              | Oudin, L., Andréassian, V., Mathevet, T., Perrin, C., & Michel, C. (2006). Dynamic averaging of rainfall‐runoff model simulations from complementary model parameterizations. Water Resources  Research, 42(7).|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "nwm.logNSE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Note for logNSE** &mdash; This metric takes the natural log of data values before computing NSE. The data is '_sanitized_' before the log is computed so that log does not attempt to take the logarithm of zero or a negative number. A few strategies are available concerning how to treat these observations (we could drop observations with zero or negative values, for example). The helper we use sanitizes this by way of a `clip()` function with a threshold of **0.01**. Any data value below this threshold is temporarily adjusted for the purposes of the logarithm; `log()` never operates on a value below the clip value. \n",
    "\n",
    " This threshold is adjustable if you would prefer to clip at a different value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nwm.logNSE(threshold=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that you can't clip to zero or a negative number\n",
    "nwm.logNSE(threshold=-0.45)\n",
    "# The benchmark will assume that's a typo and fall back to the default threshold of 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly &mdash; this data sanitization is handled differently within other libraries, notably `hydroeval`.  That package uses a slightly more complex strategy to ensure that `log()` gets clean data to work on. The `hydroeval` developer \n",
    "references [Pushpalatha et al. (2012)](https://doi.org/10.1016/j.jhydrol.2011.11.055) regarding their strategy.  The details of that method are beyond scope here -- just know that if you compare results with `hydroeval`, this metric may yield very slightly different results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Bias\n",
    "| Metric                              | Reference                                                           |\n",
    "| ----- | ----- |\n",
    "| percent bias                        | A measure of the mean tendency of simulated values to be greater or less than associated observed values, units of percent |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwm.pbias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Special Note on pbias** -- as relates to `hydroeval` and other libraries.\n",
    "* The result we compute here mimics the behavior of the `hydroGOF` R package, and is the result of the code provided in \n",
    "the [model notebook](https://github.com/USGS-python/hytest-evaluation-workflows/blob/main/gallery/streamflow/02_nwm_benchmark_analysis.ipynb) \n",
    "mentioned above. \n",
    "* This differs from the `hydroeval` Python package in an important way.  \n",
    "* `hydroGOF` (and this benchmark) returns:  <br> $100 × \\frac{\\sum_{i=1}^{n}(\\hat{x}_{i} - x_{i})}{\\sum_{i=1}^{n}x_{i}}$ <br>where $x$ is 'observed' and $\\hat{x}$ is 'modeled'\n",
    "\n",
    "* `hydroeval` on the other hand, returns:  <br> $100 × \\frac{\\sum_{i=1}^{n}(x_{i} - \\hat{x}_{i})}{\\sum_{i=1}^{n}x_{i}}$<br>Note\n",
    "  tht the numerator has switched the ordering of $x$ and $\\hat{x}$. \n",
    "\n",
    "The end result is that these two libraries return values of different sign. `hydroGOF` returns a positive value if the 'modeled' tends to be higher than 'observed', while `hydroeval` will return a negative number in this case. The absolute value of these calulations are the same. \n",
    "\n",
    "The developer for `hydroeval` points to [this document](https://elibrary.asabe.org/abstract.asp?aid=23153) as the source of the math used in that package. \n",
    "\n",
    "This code library uses the same ordering as `hydroGOF`, which is describe in EQN A1 of Yilmaz et al. (2008)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FDC - Flow Duration Curves\n",
    "| Metric | Reference |\n",
    "| ----- | ----- |\n",
    "| percent bias in midsegment slope of the flow-duration curve (FDC) between Q20-Q70 | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC low-segment volume (Q0-Q30) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "| percent bias in FDC high-segment volume (Q98-Q100) | Yilmaz, K. K., Gupta, H. V., & Wagener, T. (2008). A process‐based diagnostic approach to model evaluation: Application to the NWS distributed hydrologic model. Water Resources Research, 44(9).      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pBiasFMS** - %bias over mid-segment slope. This is the percent bias of the **slope** of the FDC in the mid-segment part of the curve. See equation A2 of Yilmaz\n",
    "\n",
    "$\\%BiasFMS = 100 × \\cfrac{ [log(QS_{m1}) - log(QS_{m2})] - [log(QO_{m1}) - log(QO_{m2})] }\n",
    "                         { [log(QO_{m1}) - log(QO_{m2})] }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mid-Segment slope %bias\n",
    "nwm.pBiasFMS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot FDC\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=300)\n",
    "nwm.FDCplot(ax, segment='mid')\n",
    "ax.set_title(\"Mid-Segment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**pBiasFLV** - %bias in low-flow segment **volume**.  Note that in low flow segment, a log transform is used to increase sensitivity to very low flows.\n",
    "\n",
    "$\\%BiasFHV = -100 × \\cfrac{\n",
    "    \\displaystyle\\sum_{l=1}^L[log(QS_l) - log(QS_L)] - \n",
    "    \\displaystyle\\sum_{l=1}^L[log(QO_l) - log(QO_l)]\n",
    "    }{\n",
    "        \\displaystyle\\sum_{l=1}^L[log(QO_l) - log(QO_L)]\n",
    "    }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-Volume Segment %bias\n",
    "nwm.pBiasFLV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=300)\n",
    "nwm.FDCplot(ax, segment='lo')\n",
    "ax.set_title(\"Low-Flow Segment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**pBiasFHV** - %bias in high-flow segment **volume**.  See equation A3 of Yilmaz\n",
    "\n",
    "\n",
    "$100 × \\cfrac{\n",
    "    \\displaystyle\\sum_{h=1}^H(QS_h - QO_h)\n",
    "    }{\n",
    "    \\displaystyle\\sum_{h=1}^H QO_h\n",
    "    }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High-Volume Segment %bias\n",
    "nwm.pBiasFHV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 2), dpi=300)\n",
    "nwm.FDCplot(ax, segment='hi')\n",
    "ax.set_title(\"High-Flow Segment\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little manipulation in `matplotlib`, all three FDC plots can be rendered in a single figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(9, 3), dpi=600)\n",
    "\n",
    "nwm.FDCplot(ax[1], segment='mid')\n",
    "ax[1].set_title(\"Mid-Segment\")\n",
    "\n",
    "nwm.FDCplot(ax[0], segment='lo')\n",
    "ax[0].set_title(\"Low-Flow\")\n",
    "\n",
    "nwm.FDCplot(ax[2], segment='hi')\n",
    "ax[2].set_title(\"High-Flow\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full NWM Standard Suite\n",
    "A single call to the `Benchmark`'s `suite()` method can report the entire suite as one series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwm.suite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "4100cc85ffefb381c538d28dd18cb927e5a99f05bbed6aaad5313d7bb1c2079e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
